import os
import pandas as pd
import argparse
import sys
import re
import numpy as np
import glob
import enum

parser = argparse.ArgumentParser()
parser.add_argument('-ws_1', action='store', required=True, help='Path to worksheet 1 output files include TSHC_<ws>_version dir')
parser.add_argument('-ws_2', action='store', help='Path to worksheet 2 output files include TSHC_<ws>_version dir')
parser.add_argument('-out_dir', action='store', help='Specifing an output directory to store html reports')
parser.add_argument('-samplesheet', action='store', help='SampleSheet requrired for HO panel quality checks')
args = parser.parse_args()



def get_inputs(ws_1, ws_2):
    '''
    All TSHC runs are conducted in pairs. The get_inputs function defines the
    following variables for a paired set of outputs:
        2) xls_rep_2- excel report (1st w/s in pair) 
        3) neg_rep- excel report for negative samples (1 per pair)
        4) fastq_bam_1 - fastq-bam comparison excel report (1st w/s in pair) 
        5) fastq_bam_2 - fastq-bam comparison excel report (2nd w/s in pair) 
        6) kin_xls - kinship report for pair
        7) vcf_dir_1 - path to vcf output directory (1st w/s in pair)
        8) vcf_dir_2  - path to vcf output directory (2nd w/s in pair)
        9) cmd_log_1 - command run text file (1st w/s in pair)
        10) cmd_log_2 - command run text file (2nd w/s pair)
        11) Panel - Name of panel

    TODO- Moving panel assignment out of this function.

    '''

    ws_1_run_info = re.search(r'\/(\w{4,7})_(\d{6})_(v[\.]?\d\.\d\.\d)\/', ws_1)    
    ws_2_run_info = re.search(r'\/(\w{4,7})_(\d{6})_(v[\.]?\d\.\d\.\d)\/', ws_2)  

    if ws_1_run_info == None or ws_2_run_info == None:
        raise Exception('Run information not available! Check regex pattern.')

    ws_1_panel = ws_1_run_info.group(1)
    ws_1_name = ws_1_run_info.group(2)
    ws_1_version = ws_1_run_info.group(3)
    ws_2_panel = ws_2_run_info.group(1)
    ws_2_name = ws_2_run_info.group(2)
    ws_2_version = ws_2_run_info.group(3)
    
    if ws_1_panel == ws_2_panel:
        panel = ws_1_panel
    else:
        raise Exception('Panels from ws_1 and ws_2 do not match!')

    # defining excel inputs
    ws_1_excel_reports = ws_1 + 'excel_reports_{}_{}/'.format(ws_1_panel, ws_1_name)
    ws_1_list = pd.DataFrame(os.listdir(ws_1_excel_reports), columns=['sample_name'])
    ws_2_excel_reports = ws_2 + 'excel_reports_{}_{}/'.format(ws_2_panel, ws_2_name)
    ws_2_list = pd.DataFrame(os.listdir(ws_2_excel_reports), columns=['sample_name'])

    xls_rep_1 = ws_1_list[~ws_1_list['sample_name'].str.contains('Neg|-fastq-bam-check|merged-variants')]
    xls_rep_2 = ws_2_list[~ws_2_list['sample_name'].str.contains('Neg|-fastq-bam-check|merged-variants')]
    neg_rep_1 = ws_1_list[ws_1_list['sample_name'].str.contains('Neg')]
    neg_rep_2 = ws_2_list[ws_2_list['sample_name'].str.contains('Neg')]
    fastq_xls_1 = ws_1_list[ws_1_list['sample_name'].str.contains('fastq-bam-check')]
    fastq_xls_2 = ws_2_list[ws_2_list['sample_name'].str.contains('fastq-bam-check')]

    xls_rep_1 = ws_1_excel_reports + xls_rep_1.values[0][0]
    xls_rep_2 = ws_2_excel_reports + xls_rep_2.values[0][0]

    #determine which ws contains the negative sample
    if len(neg_rep_1) != 0:
        neg_rep = ws_1_excel_reports + neg_rep_1.values[0][0]
    elif len(neg_rep_2) != 0:
        neg_rep = ws_2_excel_reports + neg_rep_2.values[0][0]
    else:
        raise Exception('Error the negative sample is not present!')

    # get fastq-bam-check file names 
    fastq_bam_1 = ws_1_excel_reports + fastq_xls_1.values[0][0]
    fastq_bam_2 = ws_2_excel_reports + fastq_xls_2.values[0][0]

    # defining vcf directory path 
    vcf_dir_1 = ws_1 + 'vcfs_{}_{}/'.format(ws_1_panel, ws_1_name)
    vcf_dir_2 = ws_2 + 'vcfs_{}_{}/'.format(ws_2_panel, ws_2_name)

    # defining cmd_log and kin
    cmd_log_1 = ws_1 + '{}.commandline_usage_logfile'.format(ws_1_name)
    cmd_log_2 = ws_2 + '{}.commandline_usage_logfile'.format(ws_2_name)
    kin_xls = ws_1 + '{}_{}.king.xlsx'.format(ws_1_name, ws_2_name)
    

    return xls_rep_1, xls_rep_2, neg_rep, fastq_bam_1, fastq_bam_2, kin_xls, vcf_dir_1, vcf_dir_2, cmd_log_1, cmd_log_2, panel



def results_excel_check(res, check_result_df):
    '''
    2 independent checks are completed on each excel report generated by the pipeline:
        a) 20x coverage check- Column V of the 'Hyb-QC' tab. PASS if all samples >96% (excludes D00-00000)
        b) VerifyBamId check- Coulmn I of the 'VerifyBamId' tab. PASS if all samples <3% 
    A description of the checks and a PASS/FAIL result for a given check are then added to the check_result_df
    '''

    xls = pd.ExcelFile(res)
    hybqc_df = pd.read_excel(xls, 'Hyb-QC')
    verify_bam_id_df = pd.read_excel(xls, 'VerifyBamId')
    
    work_num = os.path.basename(res)
    worksheet_name = re.search(r'\d{6}', work_num)[0]
    
    # list of all % coverage at 20x (excluding control) 
    coverage_list = hybqc_df[~hybqc_df['Sample'].str.contains('D00-00000')]['PCT_TARGET_BASES_20X'].values
    coverage_check = '20x coverage check'
    coverage_check_des = 'A check to determine if 96% of all target bases in each sample are covered at >=20X'
    coverage_result = 'PASS'

    for value in coverage_list:
        if value < 0.96:
            coverage_result = 'FAIL'
            
    #list all VerifyBamId results (inc control)
    verify_bam_list = verify_bam_id_df['%CONT'].values
    verify_bam_check = 'VerifyBamId check'
    verify_bam_check_des = 'A check to determine if all samples in a worksheet have contamination <3%'
    verify_bam_result = 'PASS'
    for value in verify_bam_list:
        if value >= 3:
            verify_bam_result = 'FAIL'
    
    check_result_df = check_result_df.append({'Check': verify_bam_check,
                            'Description': verify_bam_check_des,
                            'Result': verify_bam_result, 'Worksheet': worksheet_name}, ignore_index=True)
    
    check_result_df = check_result_df.append({'Check': coverage_check,
                            'Description': coverage_check_des,
                            'Result': coverage_result, 'Worksheet':worksheet_name}, ignore_index=True)
    
    return check_result_df
    
    
def neg_excel_check(neg_xls, check_result_df):
    '''
    2 independent checks on the negative sample excel report produced by the pipeline run (1 per pair):
        a) Numer of exons- In the 'Coverage-exon' tab 1204 exons should be present
        b) Max number of reads in negative- In column M of the 'Coverage-exon' no max should be > 0

    A description of the checks and a PASS/FAIL result for a given check are then added to the check_result_df
    '''
    
    work_num = os.path.basename(neg_xls)
    worksheet_name = re.search(r'\d{6}', work_num)[0]
    
    xls = pd.ExcelFile(neg_xls)
    neg_exon_df = pd.read_excel(xls, 'Coverage-exon')

    # number of exons check
    num_exons_check = 'Number of exons in negative sample'
    num_exons_check_des = 'A check to determine if 1207 exons are present in the negative control (Coverage-exon tab)'
    
    if len(neg_exon_df) == 1207:
        num_exons_check_result = 'PASS'
    else:
        num_exons_check_result = 'FAIL'
    
    cov_neg_exons_check = 'Contamination of negative sample'
    cov_neg_exons_check_des = 'A check to determine if the max read depth of the negative sample is equal to 0'
    max_neg_coverage = neg_exon_df['Max'].values

    over_1x = []
    for depth in set(max_neg_coverage):
        if depth >= 1:
            over_1x.append(depth)

    if len(over_1x) >= 1:
        cov_neg_exons_check_result = 'FAIL'
    else:
        cov_neg_exons_check_result = 'PASS'


    check_result_df = check_result_df.append({'Check': num_exons_check,
                                                'Description': num_exons_check_des,
                                                'Result': num_exons_check_result,
                                                'Worksheet': worksheet_name}, ignore_index=True)

    check_result_df = check_result_df.append({'Check': cov_neg_exons_check,
                                                'Description': cov_neg_exons_check_des,
                                                'Result': cov_neg_exons_check_result,
                                                'Worksheet': worksheet_name}, ignore_index=True)
    
    return check_result_df



def kinship_check(kin_xls, check_result_df):
    '''
    A check to determine if any sample the kinship.xls file has a kinship values of >=0.48
    A description of the check and a PASS/FAIL result for the check is then added to the check_result_df
    '''
    worksheet_name = re.search(r'\/(\d{6}_\d{6}).king.xlsx.*', kin_xls).group(1)

    kinship_check = 'Kinship check'
    kinship_check_des = 'A check to ensure that all samples in a worksheet pair have a kinship value of <0.48'
    
    xls = pd.ExcelFile(kin_xls)
    kinship_df = pd.read_excel(xls, 'Kinship')
    
    kinship_values = kinship_df['Kinship'].values
    
    if max(kinship_values) >= 0.48:
        kinship_check_result = 'FAIL'
    else:
        kinship_check_result = 'PASS'
    
    # Additional step to set fail for any kinship result containing inf and nan values 
    for kin in kinship_values:
        if np.isnan(kin) == True or np.isinf(kin) == True:
            kinship_check_result = 'FAIL'
    
    check_result_df = check_result_df.append({'Check': kinship_check,
                                                'Description': kinship_check_des,
                                                'Result': kinship_check_result,
                                                'Worksheet': worksheet_name}, ignore_index=True)
    
    return check_result_df



def vcf_dir_check(vcf_dir, check_result_df):
    '''
    A check to see if 48 VCF files have been generated
    A description of the check and a PASS/FAIL result for the check is then added to the check_result_df
    '''

    worksheet_name = str(re.search(r'\/vcfs_\w{4}_(\d{6})\/', vcf_dir).group(1))
    vcf_dir_check = 'VCF file count check'
    vcf_dir_check_des = 'A check to determine if 48 VCFs have been generated'
    
    if len(os.listdir(vcf_dir)) == 48:
        vcf_dir_check_result = 'PASS'
    else:
        vcf_dir_check_result = 'FAIL'
    
    check_result_df = check_result_df.append({'Check': vcf_dir_check,
                                                'Description': vcf_dir_check_des,
                                                'Result': vcf_dir_check_result,
                                                'Worksheet': worksheet_name}, ignore_index=True)
    
    return check_result_df


def fastq_bam_check(fastq_xls, check_result_df):
    '''
    A check to determine that the expected number of reads are present in each FASTQ and BAM file
    A description of the check and a PASS/FAIL result for the check is then added to the check_result_df
    '''
    
    work_num = os.path.basename(fastq_xls)
    worksheet_name = re.search(r'\d{6}', work_num)[0]
    

    fastq_bam_check = 'FASTQ-BAM check'
    fastq_bam_check_des = 'A check to determine that the expected number of reads are present in each FASTQ and BAM file'
    xls = pd.ExcelFile(fastq_xls)
    fastq_bam_df = pd.read_excel(xls, 'Check')
    fastq_bam = set(fastq_bam_df['Result'].values)

    if 'FAIL' in fastq_bam:
        fastq_bam_check_result = 'FAIL'
    else:
        fastq_bam_check_result = 'PASS'
    
    check_result_df = check_result_df.append({'Check': fastq_bam_check,
                                                'Description': fastq_bam_check_des,
                                                'Result': fastq_bam_check_result,
                                                'Worksheet': worksheet_name}, ignore_index=True)

    return check_result_df

def generate_html_output(check_result_df, run_details_df, panel, bed_1, bed_2):
    '''
    Creating a static HTML file to display the results to the Clinical Scientist reviewing the quality check report.
    This function calls the format_bed_files function to add in bed file information.
    This process involves changes directly to the html. TODO find replacement method to edit html.
    '''

    with open('css_style.css') as file:
        style = file.read()
    run_details = run_details_df.to_html(index=False, justify='left')
    run_details = format_bed_files(run_details, bed_1, bed_2)
    check_details = check_result_df.to_html(index=False, justify='left')

    report_head = f'<h1>{panel} Quality Report</h1>'
    run_sub = '<h2>Run details<h2/>'
    check_sub = '<h2>Checks<h2/>'
    html = f'<!DOCTYPE html><html><head>{style}</head><body>{report_head}{run_sub}{run_details}{check_sub}{check_details}</body></hml>'

    # Add class to PASS/FAIL to colour code
    html = re.sub(r"<td>PASS</td>",r"<td class='PASS'>PASS</td>", html)
    html = re.sub(r"<td>FAIL</td>",r"<td class='FAIL'>FAIL</td>", html)

    file_name = "_".join(run_details_df['Worksheet'].values.tolist()) + '_quality_checks.html'

    return file_name, html


def format_bed_files(run_html, bed_1, bed_2):
    '''
    Adding the bed file html table to the run html table. The bed file information is passed as 
    a list for each worksheet in the pair. [ws_1_html, search_term]. The html contains bed file
    information for the worksheet e.g. target bed, refined bed and coverage bed... This is then
    substituted into the html by searching for the ws search term e.g. 000001_bed_files.
    '''

    bed_1_html = bed_1[0]
    bed_1_search = bed_1[1]
    bed_2_html = bed_2[0]
    bed_2_search = bed_2[1]
    run_html = re.sub(f'{bed_1_search}', f'{bed_1_html}', run_html)
    run_html = re.sub(f'{bed_2_search}', f'{bed_2_html}', run_html)

    # rename dataframe bed_table to bed_table... css classes cannot have spaces
    run_html = re.sub('<td><table border="1" class="dataframe bed_table">', '<td><table border="1" class="bed_table">', run_html)

    return run_html

def run_details(cmd,xls_rep,run_details_df):
    '''
    Collect the following run details from the commandline_usage_logfile and excel report
        1) CMD log file- Worksheet number and experiment name
        2) excel report- Worksheet number, AB threshold, pipeline version and BED files
    Add run details to run details_df
    '''
    bed_files = []
    bed_df = pd.DataFrame(columns=['Target bed', 'Refined bed', 'Coverage bed'])

    # get ws names for the cmd file and
    cmd_ws = re.search(r'(\d{6})\.commandline_usage_logfile', cmd)
    xls_ws = re.search(r'(\d{6})-\d{2}-D\d{2}-\d{5}-\w{2,3}-\w+-\d{3}_S\d+\.v\d\.\d\.\d-results\.xlsx', xls_rep)

    if cmd_ws == None:
        raise Exception('Input error- issue with commandline_usage_logfile')
    elif xls_ws == None:
        raise Exception('Input error- xls input worksheet not present.')

    cmd_ws = cmd_ws.group(1)
    xls_ws = xls_ws.group(1)

    # check that the cmd and xls report are from the same worksheet
    if cmd_ws != xls_ws:
        raise Exception('The worksheet numbers: {} and {} do not match!'.format(cmd_ws, xls_ws))

    worksheet = cmd_ws

    # get experiment name from command output
    with open(cmd, 'r') as file:
        cmd_text = file.read()
    search_term = r'-s\s\n\/network\/sequenced\/MiSeq_data\/\w{4,7}\/(shire_worksheet_numbered|Validation)\/(?:200000-299999\/)?(?:300000-399999\/)?' + re.escape(worksheet) + r'\/(\d{6}_M\d{5}_\d{4}_\d{9}-\w{5})\/SampleSheet.csv'

    experiment_name = re.search(search_term, cmd_text).group(2)
    
    if experiment_name == None:
        raise Exception('The experiment name is not present! check regex pattern.')

    # get pipeline version, bed file names and AB threshold
    xls = pd.ExcelFile(xls_rep)
    config_df = pd.read_excel(xls, 'config_parameters')
    allele_balance = config_df[config_df['key']=='AB_threshold']['variable'].values[0]
    pipe_version = config_df[config_df['key']=='pipeline version']['variable'].values[0]
    target_bed = config_df[config_df['key']=='target_regions']['variable'].values[0].split('/')[-1]
    refined_target_bed = config_df[config_df['key']=='refined_target_regions']['variable'].values[0].split('/')[-1]
    coverage_bed = config_df[config_df['key']=='coverage_regions']['variable'].values[0].split('/')[-1]

    bed_file_table = f'{worksheet}_bed_files'

    bed_df = bed_df.append({
        'Target bed': target_bed,
        'Refined bed': refined_target_bed,
        'Coverage bed': coverage_bed
        }, ignore_index=True)

    bed_df = bed_df.transpose()
    bed_html = bed_df.to_html(justify='left', header=None, escape=True, classes='bed_table', border=0)

    bed = [bed_html, bed_file_table]

    run_details_df = run_details_df.append({'Worksheet': worksheet,
                                            'Pipeline version': pipe_version,
                                            'Experiment name': experiment_name,
                                            'Bed files': bed_file_table,
                                            'AB threshold': allele_balance
                                            }, ignore_index=True)

    return run_details_df, bed

def tshc_main(ws_1, ws_2):
    '''
    A function to organise the TSHC output quality check function calls

    '''

    xls_rep_1, xls_rep_2, neg_rep, fastq_bam_1, fastq_bam_2, kin_xls, vcf_dir_1, vcf_dir_2, cmd_log_1, cmd_log_2, panel = get_inputs(ws_1, ws_2)

    pd.set_option('display.max_colwidth', -1)
    check_result_df = pd.DataFrame(columns=[ 'Worksheet','Check', 'Description','Result'])
    run_details_df = pd.DataFrame(columns=['Worksheet', 'Pipeline version', 'Experiment name', 'Bed files', 'AB threshold'])

    # ws_1 checks
    check_result_df = results_excel_check(xls_rep_1, check_result_df)
    check_result_df = vcf_dir_check(vcf_dir_1, check_result_df)
    check_result_df = fastq_bam_check(fastq_bam_1, check_result_df)

    # ws_2 checks
    check_result_df = results_excel_check(xls_rep_2, check_result_df)
    check_result_df = vcf_dir_check(vcf_dir_2, check_result_df)
    check_result_df = fastq_bam_check(fastq_bam_2, check_result_df)

    # pair checks
    check_result_df = neg_excel_check(neg_rep, check_result_df)
    check_result_df = kinship_check(kin_xls, check_result_df)

    # run details
    run_details_df, bed_1 = run_details(cmd_log_1, xls_rep_1, run_details_df)
    run_details_df, bed_2 = run_details(cmd_log_2, xls_rep_2, run_details_df)

    # sort
    check_result_df = check_result_df.sort_values(by=['Worksheet'])
    run_details_df = run_details_df.sort_values(by=['Worksheet'])
    #create static html output
    name, html_report = generate_html_output(check_result_df,run_details_df, panel, bed_1, bed_2)

    # write html report to both results directories
    ws_1_out = args.ws_1
    ws_2_out = args.ws_2

    if args.out_dir == None:
        os.chdir(ws_1_out)
        with open(name, 'w') as file:
            file.write(html_report)
        os.chdir(ws_2_out)
        with open(name, 'w') as file:
            file.write(html_report)
    else:
        print(f'Saving html reports to {args.out_dir}')
        os.chdir(args.out_dir)
        with open(name, 'w') as file:
            file.write(html_report)

def assign_panel(ws_1, ws_2, sample_sheet):
    '''
    Assiging a panel and <panel>_main funtion to process pipeline output.
    
    TODO --> For now I have implemented this for TSMP... other panels to follow

    '''
    panel = re.search(panel_regex, ws_1).group(1)

    if panel == 'TSMP':
        ho_main(panel, ws_1, sample_sheet)
    elif panel == 'TSHC':
        tshc_main(ws_1, ws_2)
    else:
        print('Are you sure....Never heard of this panel')


def ho_main(panel, ws_1, sample_sheet):
    '''
    A function to organise the HO function calls

    The following functions must be run to produce the quality check report:

    1. Assign varaiables for samples in worksheet (sort_ho_inputs)
    2. get_run details table 
    3. Run 9 independent checks and create output df

    '''

    result_files = sort_ho_inputs(panel, ws_1, sample_sheet)
    run_details_df = run_details_ho(result_files)

    #create df and add results for each check
    ho_check_result_df = pd.DataFrame(columns=[ 'Worksheet','Check', 'Description','Result', 'Info'])    
    ho_check_result_df = ho_vcf_check(result_files, ho_check_result_df)
    ho_check_result_df = ho_neg_checks(result_files, ho_check_result_df)
    ho_check_result_df = verifybamid_check(result_files, ho_check_result_df)

    print(ho_check_result_df)

    # to access Max value
    #print(ho_vcf_check_df['Info'][0]['Max'])

    # sample_1_xls = pd.ExcelFile(sample_1)
    # hybqc = pd.read_excel(sample_1_xls, 'Hyb-QC')

    pass

def sort_ho_inputs(panel, ws_1, sample_sheet):
    '''
    a function to a dictionary of inputs

    TODO- handle ~lock xls if samples open

    For the majority of checks use sample_1 one, for FLT3 check use whole list.
    '''

    worksheet = re.search(panel_regex, ws_1).group(2)

    if sample_sheet == None:
        raise Exception("A samplesheet has not been provided... check the command")


    pat_results_list = []

    excel_base = ws_1 + f'excel_reports_{panel}_{worksheet}/'
    results_list = os.listdir(excel_base)
    excel_df = pd.DataFrame(results_list, columns=['sample_name'])    

    # TODO check that SRY output is capitalised
    # sort all results
    neg_xls = excel_df[excel_df['sample_name'].str.contains('Neg|NEG')]
    pat_results = excel_df[~excel_df['sample_name'].str.contains('Neg|NEG|-fastq-bam-check|merged-variants|SRY')]
    sry_xls = excel_df[excel_df['sample_name'].str.contains('SRY')]
    merged_xls = excel_df[excel_df['sample_name'].str.contains('merged-variants')]

    # get abs path for each df
    neg_xls = f'{excel_base}'+ neg_xls['sample_name'].squeeze()
    pat_results = pat_results.squeeze().to_list()
    for res in pat_results:
        res_path = f'{excel_base}' + res
        pat_results_list.append(res_path)
    cmd_log_file = os.path.abspath(ws_1) + f'/{worksheet}.commandline_usage_logfile'
    vcf_dir = os.path.abspath(ws_1) + f'/vcfs_{panel}_{worksheet}/'
    if sry_xls.empty == True:
        sry_xls = None
    else:
        sry_xls = os.path.abspath(sry_xls.squeeze())
    merged_xls = os.path.abspath(merged_xls.squeeze())

    ho_inp =     {
    'panel': panel,
    'worksheet': worksheet,
    'negative': neg_xls,
    'pat_results': pat_results_list, 
    'cmd_log_file': cmd_log_file,
    'vcf_directory': vcf_dir,
    'sry_excel': sry_xls,
    'merged_variant_xls': merged_xls,
    'sample_sheet': sample_sheet
    }

    return ho_inp

def run_details_ho(ho_inp):
    '''
    Retrieve run details information from command line log file
    '''

    panel = ho_inp['panel']
    cmd = ho_inp['cmd_log_file']
    worksheet = ho_inp['worksheet']
    with open(cmd, 'r') as file:
        cmd_text = file.read()

    exp_term = r'-s\s\n\/network\/sequenced\/MiSeq_data\/Nextera_Rapid_Capture\/TruSight_Myeloid_Panel_v3\/(shire_worksheet_numbered|Validation)\/(?:200000-299999\/)?(?:300000-399999\/)?' + re.escape(worksheet) + r'\/(\d{6}_M\d{5}_\d{4}_\d{9}-\w{5})\/SampleSheet.csv'
    pipe_term = r'Pipeline\scommand:\n\/opt\/scripts\/MiSeq-Universal-(v[\.]?\d\.\d\.\d)\/MiSeq-master-pipeline.py'
    exp_name = re.search(exp_term, cmd_text).group(2)
    pipe_version = re.search(pipe_term, cmd_text).group(1)

    ho_run_details_df = pd.DataFrame(columns=['Worksheet', 'Panel', 'Pipeline version', 'Experiment name'])

    ho_details_df = ho_run_details_df.append({'Worksheet': worksheet,
                                            'Panel': panel,
                                            'Pipeline version': pipe_version,
                                            'Experiment name': exp_name
                                            }, ignore_index=True)

    return ho_details_df

def ho_vcf_check(ho_inp, ho_check_result_df):
    '''
    A check to determine if the number of VCFs generated
    is 2x the number of samples in the sample sheet

    TODO check that the index value of 20 does not change between samplesheets!
    '''
    sample_sheet_path = ho_inp['sample_sheet']
    vcf_dir_path = ho_inp['vcf_directory']
    sample_sheet_xls = pd.read_csv(sample_sheet_path)
    # split sample sheet into section containing sample names
    column_list = sample_sheet_xls.iloc[19:20].squeeze().to_list()
    sample_df = pd.DataFrame(sample_sheet_xls.iloc[20:])
    sample_df.columns = column_list

    num_sample = sample_df['Sample_ID'].count()
    num_exp = num_sample * 2

    vcf_search = vcf_dir_path + '*.vcf'
    vcf_files = glob.glob(vcf_search)

    file_size = []
    for file in vcf_files:
        size = os.stat(file).st_size
        file_size.append(size)

    min_file = convert_unit(min(file_size))
    max_file = convert_unit(max(file_size))
    file_size_df = pd.DataFrame(columns=[ 'Min','Max'])
    file_size_df = file_size_df.append({
        'Min': min_file,
        'Max': max_file
        }, ignore_index=True)

    worksheet = ho_inp['worksheet']
    vcf_check = 'VCF count check'
    vcf_check_des = 'The number of VCFs produced must be 2 times the number of \
    samples present on the samplesheet'

    if num_exp != len(vcf_files):
        vcf_check_res = 'FAIL'
    else:
        vcf_check_res = 'PASS'

    ho_check_result_df = ho_check_result_df.append({'Check': vcf_check,
                                            'Description': vcf_check_des,
                                            'Result': vcf_check_res,
                                            'Worksheet': worksheet,
                                            'Info': file_size_df}, ignore_index=True)

    return ho_check_result_df


def convert_unit(size_in_bytes, unit='KB'):
    '''
    A function to convert size of VCFs from bytes to human readable format
    '''

    if unit == 'KB':
       return str(int(size_in_bytes/1024)) + ' KB'
    elif unit == 'MB':
       return str(int(size_in_bytes/(1024*1024))) + ' MB' 
    elif unit == 'GB':
       return str(int(size_in_bytes/(1024*1024*1024))) + ' GB'
    else:
        return str(size_in_bytes) + ' B'

def ho_neg_checks(ho_inp, ho_check_result_df):
    '''
    Completes 3 checks on the negative excel file: 
    1) Number of exons present in the negative excel file (coverage-exon tab)
    2) If any exon in the negative sample has a depth > 30
    3) If the maximum depth in the negative sample == 0

    A pass/fail criteria is applied and the results are added to the ho_check_results_df
    '''

    panel = ho_inp['panel'] 
    if panel == 'TSMP':
        exon_target = 491
    elif panel == 'CLL':
        exon_target = 148
    else:
        raise Exception('This panel has not been added to this script.')

    neg_xls_path = ho_inp['negative']
    xls = pd.ExcelFile(ho_inp['negative'])
    neg_exon_df = pd.read_excel(xls, 'Coverage-exon')
    num_exons = neg_exon_df['Max'].count()

    worksheet = ho_inp['worksheet']
    neg_exon_check = 'Negative exon check'
    neg_exon_check_des = f'There are {exon_target} exons present in the negative sample.'
    info = None

    # Number of exons present depends on panel
    if panel == 'TSMP' and num_exons == 491:
        neg_exon_res = 'PASS'
    elif panel == 'CLL' and num_exons == 148:
        neg_exon_res = 'PASS'
    else:
        neg_exon_res = 'FAIL'

    max_num_exons = neg_exon_df['Max'].max()
    neg_depth_check = 'Negative exon depth check'
    neg_depth_check_des = f'The maximum depth of each exon of the negative sample \
    does not exceed 30 reads.'

    if max_num_exons > 30:
        neg_depth_res = 'FAIL'
    else:
        neg_depth_res = 'PASS'

    neg_zero_check = 'Negative exon depth check > 0'
    neg_zero_check_des = f'The maximum number of reads in each exon of the negative \
    sample is greater than 0.'    

    if max_num_exons > 0:
        neg_zero_res = 'PASS'
    else:
        neg_zero_res = 'FAIL'

    ho_check_result_df = ho_check_result_df.append({'Check': neg_exon_check,
                                            'Description': neg_exon_check_des,
                                            'Result': neg_exon_res,
                                            'Worksheet': worksheet,
                                            'Info': info}, ignore_index=True)
   
    ho_check_result_df = ho_check_result_df.append({'Check': neg_depth_check,
                                            'Description': neg_depth_check_des,
                                            'Result': neg_depth_res,
                                            'Worksheet': worksheet,
                                            'Info': info}, ignore_index=True)

    ho_check_result_df = ho_check_result_df.append({'Check': neg_zero_check,
                                            'Description': neg_zero_check_des,
                                            'Result': neg_zero_res,
                                            'Worksheet': worksheet,
                                            'Info': info}, ignore_index=True)

    return ho_check_result_df

def verifybamid_check(ho_inp, ho_check_result_df):
    '''
    Checks the verifybamid tab to ensure samples do not exceed contamination thresholds:
        CLL > 3%
        MPN > 10%
        TSMP > ?
    TODO- Check the threshold for TSMP panel sample. For now the value is 3%. Is this correct?
    '''

    panel = ho_inp['panel']
    
    if panel == 'MPN':
        threshold = 10.0
    else:
        threshold = 3.0

    # pick the first sample results xls verifybamid common across samples 
    xls_path = ho_inp['pat_results'][0]
    xls = pd.ExcelFile(xls_path)
    verifybamid_df = pd.read_excel(xls, 'VerifyBamId')

    max_cont = verifybamid_df['%CONT'].max()

    worksheet = ho_inp['worksheet']
    verifybamid_check = 'VerifyBamId check'
    verifybamid_check_des = f'Percentage contamination is below {int(threshold)}%'
    info = None

    if max_cont > threshold:
        verifybamid_res = 'FAIL'
    else:
        verifybamid_res = 'PASS'

    ho_check_result_df = ho_check_result_df.append({'Check': verifybamid_check,
                                            'Description': verifybamid_check_des,
                                            'Result': verifybamid_res,
                                            'Worksheet': worksheet,
                                            'Info': info}, ignore_index=True)

    return ho_check_result_df

# Generic regex used to extact ws_num etc
# TODO replace TSHC section with variable name
panel_regex = r'\/(\w{4,7})_(\d{6})_(v[\.]?\d\.\d\.\d)\/'

ws_1 = args.ws_1
ws_2 = args.ws_2
sample_sheet = args.samplesheet

# Assign panel and start workflow
assign_panel(ws_1, ws_2, sample_sheet)


#tshc_main(ws_1, ws_2)